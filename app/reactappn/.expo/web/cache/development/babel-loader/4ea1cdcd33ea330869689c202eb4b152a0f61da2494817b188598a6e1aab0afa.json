{"ast":null,"code":"import _slicedToArray from \"@babel/runtime/helpers/slicedToArray\";\nimport React, { useState, useEffect } from \"react\";\nimport StyleSheet from \"react-native-web/dist/exports/StyleSheet\";\nimport Text from \"react-native-web/dist/exports/Text\";\nimport View from \"react-native-web/dist/exports/View\";\nimport ImageBackground from \"react-native-web/dist/exports/ImageBackground\";\nimport Modal from \"react-native-web/dist/exports/Modal\";\nimport Button from \"react-native-web/dist/exports/Button\";\nimport Linking from \"react-native-web/dist/exports/Linking\";\nimport styles from \"./styles\";\nimport StyleButton from \"../StyleButton\";\nimport MicroButton from \"../MicroButton\";\nimport * as Permissions from 'expo-permissions';\nimport { Audio } from 'expo-av';\nimport { Camera } from 'expo-camera';\nimport { jsx as _jsx } from \"react/jsx-runtime\";\nimport { jsxs as _jsxs } from \"react/jsx-runtime\";\nvar EyeItem = function EyeItem() {\n  var _useState = useState(''),\n    _useState2 = _slicedToArray(_useState, 2),\n    transcript = _useState2[0],\n    setTranscript = _useState2[1];\n  var startRecognition = function startRecognition() {\n    var recognition = new window.webkitSpeechRecognition();\n    recognition.interimResults = true;\n    recognition.onresult = function (e) {\n      var interimTranscript = Array.from(e.results).map(function (result) {\n        return result[0];\n      }).map(function (result) {\n        return result.transcript;\n      }).join('');\n      setTranscript(interimTranscript);\n    };\n    recognition.start();\n    console.log(transcript);\n  };\n  if (transcript.includes('Video.')) {\n    var link = 'https://youtu.be/X4sicgZ1rus';\n    Linking.openURL(link);\n  }\n  var handleLinkPress = function handleLinkPress() {\n    console.log(transcript);\n    var link = 'https://youtu.be/X4sicgZ1rus';\n    Linking.openURL(link);\n  };\n  return _jsxs(View, {\n    style: styles.eyeContainer,\n    children: [_jsx(ImageBackground, {\n      source: require('D:\\\\Facultate Anul III\\\\SeverinReactApp\\\\reactappn\\\\assets\\\\images\\\\Backphoto2.jpg'),\n      style: styles.image\n    }), _jsxs(View, {\n      style: styles.titles,\n      children: [_jsx(Text, {\n        accessible: true,\n        accessibilityLabel: \"Title\",\n        accessibilityHint: \"We Become Your Eyes\",\n        style: styles.title,\n        children: \"We Become Your Eyes\"\n      }), _jsx(Text, {\n        accessible: true,\n        accessibilityLabel: \"Subtitle\",\n        accessibilityHint: \"Here To Help You\",\n        style: styles.subtitles,\n        children: \"Here To Help You\"\n      })]\n    }), _jsx(View, {\n      style: styles.buttonsContainer,\n      children: _jsx(StyleButton, {\n        style: {\n          bottom: '50'\n        },\n        type: \"primary\",\n        content: \"Use My Eye\",\n        onPress: handleLinkPress\n      })\n    }), _jsxs(View, {\n      accessible: true,\n      accessibilityLabel: \"Button\",\n      accessibilityHint: \"For vocal commands\",\n      style: styles.buttonRecord,\n      children: [_jsx(StyleButton, {\n        type: \"secondary\",\n        content: \"Start Recording\",\n        onPress: startRecognition\n      }), _jsx(Text, {\n        style: styles.textAs,\n        id: \"convert_text\",\n        children: transcript\n      })]\n    })]\n  });\n};\nexport default EyeItem;","map":{"version":3,"names":["React","useState","useEffect","StyleSheet","Text","View","ImageBackground","Modal","Button","Linking","styles","StyleButton","MicroButton","Permissions","Audio","Camera","jsx","_jsx","jsxs","_jsxs","EyeItem","_useState","_useState2","_slicedToArray","transcript","setTranscript","startRecognition","recognition","window","webkitSpeechRecognition","interimResults","onresult","e","interimTranscript","Array","from","results","map","result","join","start","console","log","includes","link","openURL","handleLinkPress","style","eyeContainer","children","source","require","image","titles","accessible","accessibilityLabel","accessibilityHint","title","subtitles","buttonsContainer","bottom","type","content","onPress","buttonRecord","textAs","id"],"sources":["D:/Facultate Anul III/SeverinReactApp/reactappn/components/EyeItem/index.js"],"sourcesContent":["import React,{useState,useEffect} from \"react\";\r\nimport { StyleSheet, Text, View, ImageBackground, Modal, Button,Linking} from 'react-native';\r\nimport styles from \"./styles\";\r\nimport StyleButton from \"../StyleButton\";\r\nimport MicroButton from \"../MicroButton\";\r\nimport * as Permissions from 'expo-permissions';\r\nimport { Audio } from 'expo-av';\r\nimport { Camera } from 'expo-camera';\r\n\r\n// const RECORDING_OPTIONS_PRESET_HIGH_QUALITY = {\r\n//   isMeteringEnabled: true,\r\n//   android: {\r\n//     extension: '.m4a',\r\n//     outputFormat: Audio.RECORDING_OPTION_ANDROID_OUTPUT_FORMAT_MPEG_4,\r\n//     audioEncoder: Audio.RECORDING_OPTION_ANDROID_AUDIO_ENCODER_AAC,\r\n//     sampleRate: 44100,\r\n//     numberOfChannels: 2,\r\n//     bitRate: 128000,\r\n//   },\r\n//   ios: {\r\n//     extension: '.caf',\r\n//     audioQuality: Audio.RECORDING_OPTION_IOS_AUDIO_QUALITY_MAX,\r\n//     sampleRate: 44100,\r\n//     numberOfChannels: 2,\r\n//     bitRate: 128000,\r\n//     linearPCMBitDepth: 16,\r\n//     linearPCMIsBigEndian: false,\r\n//     linearPCMIsFloat: false,\r\n//   },\r\n// };\r\n\r\nconst EyeItem=()=>{\r\n \r\n//pentru website\r\n  const [transcript, setTranscript] = useState('');\r\n\r\n  const startRecognition = () => {\r\n    const recognition = new window.webkitSpeechRecognition();\r\n    recognition.interimResults = true;\r\n\r\n    recognition.onresult = e => {\r\n      const interimTranscript = Array.from(e.results)\r\n        .map(result => result[0])\r\n        .map(result => result.transcript)\r\n        .join('');\r\n     \r\n      setTranscript(interimTranscript);\r\n      \r\n    };\r\n\r\n    recognition.start();\r\n    console.log(transcript);\r\n    \r\n    \r\n\r\n\r\n\r\n    \r\n  };\r\n  \r\n  // for phone\r\n  // const [recording, setRecording] = useState(null);\r\n  // const [isRecording, setIsRecording] = useState(false);\r\n  // const [transcript, setTranscript] = useState('');\r\n  // const audioMode = {\r\n  //   allowsRecordingIOS: true,\r\n  //   playsInSilentModeIOS: true,\r\n  //   staysActiveInBackground: true,\r\n  //   interruptionModeIOS: Audio.INTERRUPTION_MODE_IOS_MIX_WITH_OTHERS,\r\n  //   interruptionModeAndroid: Audio.INTERRUPTION_MODE_ANDROID_DO_NOT_MIX,\r\n  //   shouldDuckAndroid: true,\r\n  //   playThroughEarpieceAndroid: false,\r\n  // };\r\n\r\n\r\n  // const startRecording = async () => {\r\n  //   try {\r\n  //     console.log('Requesting permissions..');\r\n  //     const { status } = await Permissions.askAsync(Permissions.AUDIO_RECORDING);\r\n  //     if (status !== 'granted') {\r\n  //       alert('Permission to access microphone denied');\r\n  //       return;\r\n  //     }\r\n  //     console.log('Starting recording..');\r\n  //     const newRecording = new Audio.Recording();\r\n  //     await newRecording.prepareToRecordAsync(audioMode);\r\n  //     await newRecording.startAsync();\r\n  //     setRecording(newRecording);\r\n  //     setIsRecording(true);\r\n  //     console.log('Recording started');\r\n  //   } catch (err) {\r\n  //     console.error('Failed to start recording', err);\r\n  //   }\r\n  // };\r\n\r\n  // const stopRecording = async () => {\r\n  //   console.log('Stopping recording..');\r\n  //   setIsRecording(false);\r\n  //   await recording.stopAndUnloadAsync();\r\n  //   const uri = recording.getURI();\r\n  //   console.log('Recording stopped and stored at', uri);\r\n  //   await convertToText(uri);\r\n  // };\r\n\r\n  // const convertToText = async (uri) => {\r\n  //   try {\r\n  //     console.log('Converting to text..');\r\n  //     const { status } = await Permissions.askAsync(Permissions.AUDIO_RECORDING);\r\n  //     if (status !== 'granted') {\r\n  //       alert('Permission to access microphone denied');\r\n  //       return;\r\n  //     }\r\n  //     const voicePermissions = await Voice.getPermissionsAsync();\r\n  //     if (!voicePermissions.granted) {\r\n  //       await Voice.requestPermissionsAsync();\r\n  //     }\r\n  //     const { transcript } = await Voice.recognizeAsync({\r\n  //       uri,\r\n  //       language: 'en-US',\r\n  //     });\r\n  //     setTranscript(transcript);\r\n  //     console.log('Transcript:', transcript);\r\n  //   } catch (err) {\r\n  //     console.error('Failed to convert to text', err);\r\n  //   }\r\n  // };\r\n\r\n  // useEffect(() => {\r\n  //   return () => {\r\n  //     if (recording) {\r\n  //       recording.stopAndUnloadAsync();\r\n  //     }\r\n  //   };\r\n  // }, []);\r\n  //var link='';\r\n  if(transcript.includes('Video.')){\r\n    const link = 'https://youtu.be/X4sicgZ1rus';\r\n    Linking.openURL(link);\r\n    }\r\n  const handleLinkPress = () => {\r\n    // if(transcript.contains('l')){\r\n    //   link='https://youtu.be/b9eMGE7QtTk'\r\n    // }\r\n    console.log(transcript);\r\n    \r\n    const link = 'https://youtu.be/X4sicgZ1rus';\r\n    Linking.openURL(link);\r\n    \r\n  };\r\nreturn (\r\n    <View style={styles.eyeContainer}>\r\n      \r\n\r\n    <ImageBackground \r\n    \r\n    source={require('D:\\\\Facultate Anul III\\\\SeverinReactApp\\\\reactappn\\\\assets\\\\images\\\\Backphoto2.jpg')}\r\n    style={styles.image}\r\n    />\r\n\r\n    \r\n\r\n    <View style={styles.titles}>\r\n      <Text \r\n      accessible={true}\r\n      accessibilityLabel=\"Title\"\r\n      accessibilityHint=\"We Become Your Eyes\"\r\n      style={styles.title}>We Become Your Eyes</Text>\r\n      <Text \r\n      accessible={true}\r\n      accessibilityLabel=\"Subtitle\"\r\n      accessibilityHint=\"Here To Help You\"\r\n      style={styles.subtitles}>Here To Help You</Text>\r\n    </View>\r\n    {/* <View style={styles.buttMicrophone}>\r\n      <MicroButton/>\r\n\r\n    </View> */}\r\n    <View \r\n    \r\n    style={styles.buttonsContainer}>\r\n    <StyleButton style={{bottom:'50'}}\r\n    type=\"primary\" \r\n    content={\"Use My Eye\"}\r\n    onPress={handleLinkPress}\r\n   \r\n    />\r\n    </View>\r\n    <View \r\n    accessible={true}\r\n    accessibilityLabel=\"Button\"\r\n    accessibilityHint=\"For vocal commands\"\r\n    style={styles.buttonRecord}>\r\n    <StyleButton \r\n    type=\"secondary\" \r\n    content={\"Start Recording\"}\r\n    onPress={startRecognition}\r\n   \r\n    />\r\n    <Text style={styles.textAs} id=\"convert_text\">{transcript}</Text>\r\n    </View>\r\n    {/* <>\r\n  <StyleButton styles={styles.butonsContainer}\r\n    id=\"click_to_record\"\r\n    title=\"Click to Record\"\r\n    onPress={startRecognition}\r\n  />\r\n  <Text style={styles.textAs} id=\"convert_text\">{transcript}</Text>\r\n</> */}\r\n{/* <View style={styles.buttonRecord}>\r\n    <StyleButton \r\n    type=\"secondary\" \r\n    content={\"Click to Record\"}\r\n    onPress={handleLinkPress}\r\n    \r\n    />\r\n    </View> */}\r\n    \r\n  </View>\r\n);\r\n\r\n};\r\n\r\n\r\nexport default EyeItem;"],"mappings":";AAAA,OAAOA,KAAK,IAAEC,QAAQ,EAACC,SAAS,QAAO,OAAO;AAAC,OAAAC,UAAA;AAAA,OAAAC,IAAA;AAAA,OAAAC,IAAA;AAAA,OAAAC,eAAA;AAAA,OAAAC,KAAA;AAAA,OAAAC,MAAA;AAAA,OAAAC,OAAA;AAE/C,OAAOC,MAAM;AACb,OAAOC,WAAW;AAClB,OAAOC,WAAW;AAClB,OAAO,KAAKC,WAAW,MAAM,kBAAkB;AAC/C,SAASC,KAAK,QAAQ,SAAS;AAC/B,SAASC,MAAM,QAAQ,aAAa;AAAC,SAAAC,GAAA,IAAAC,IAAA;AAAA,SAAAC,IAAA,IAAAC,KAAA;AAwBrC,IAAMC,OAAO,GAAC,SAARA,OAAOA,CAAA,EAAK;EAGhB,IAAAC,SAAA,GAAoCpB,QAAQ,CAAC,EAAE,CAAC;IAAAqB,UAAA,GAAAC,cAAA,CAAAF,SAAA;IAAzCG,UAAU,GAAAF,UAAA;IAAEG,aAAa,GAAAH,UAAA;EAEhC,IAAMI,gBAAgB,GAAG,SAAnBA,gBAAgBA,CAAA,EAAS;IAC7B,IAAMC,WAAW,GAAG,IAAIC,MAAM,CAACC,uBAAuB,EAAE;IACxDF,WAAW,CAACG,cAAc,GAAG,IAAI;IAEjCH,WAAW,CAACI,QAAQ,GAAG,UAAAC,CAAC,EAAI;MAC1B,IAAMC,iBAAiB,GAAGC,KAAK,CAACC,IAAI,CAACH,CAAC,CAACI,OAAO,CAAC,CAC5CC,GAAG,CAAC,UAAAC,MAAM;QAAA,OAAIA,MAAM,CAAC,CAAC,CAAC;MAAA,EAAC,CACxBD,GAAG,CAAC,UAAAC,MAAM;QAAA,OAAIA,MAAM,CAACd,UAAU;MAAA,EAAC,CAChCe,IAAI,CAAC,EAAE,CAAC;MAEXd,aAAa,CAACQ,iBAAiB,CAAC;IAElC,CAAC;IAEDN,WAAW,CAACa,KAAK,EAAE;IACnBC,OAAO,CAACC,GAAG,CAAClB,UAAU,CAAC;EAOzB,CAAC;EA6ED,IAAGA,UAAU,CAACmB,QAAQ,CAAC,QAAQ,CAAC,EAAC;IAC/B,IAAMC,IAAI,GAAG,8BAA8B;IAC3CnC,OAAO,CAACoC,OAAO,CAACD,IAAI,CAAC;EACrB;EACF,IAAME,eAAe,GAAG,SAAlBA,eAAeA,CAAA,EAAS;IAI5BL,OAAO,CAACC,GAAG,CAAClB,UAAU,CAAC;IAEvB,IAAMoB,IAAI,GAAG,8BAA8B;IAC3CnC,OAAO,CAACoC,OAAO,CAACD,IAAI,CAAC;EAEvB,CAAC;EACH,OACIzB,KAAA,CAACd,IAAI;IAAC0C,KAAK,EAAErC,MAAM,CAACsC,YAAa;IAAAC,QAAA,GAGjChC,IAAA,CAACX,eAAe;MAEhB4C,MAAM,EAAEC,OAAO,CAAC,oFAAoF,CAAE;MACtGJ,KAAK,EAAErC,MAAM,CAAC0C;IAAM,EAClB,EAIFjC,KAAA,CAACd,IAAI;MAAC0C,KAAK,EAAErC,MAAM,CAAC2C,MAAO;MAAAJ,QAAA,GACzBhC,IAAA,CAACb,IAAI;QACLkD,UAAU,EAAE,IAAK;QACjBC,kBAAkB,EAAC,OAAO;QAC1BC,iBAAiB,EAAC,qBAAqB;QACvCT,KAAK,EAAErC,MAAM,CAAC+C,KAAM;QAAAR,QAAA,EAAC;MAAmB,EAAO,EAC/ChC,IAAA,CAACb,IAAI;QACLkD,UAAU,EAAE,IAAK;QACjBC,kBAAkB,EAAC,UAAU;QAC7BC,iBAAiB,EAAC,kBAAkB;QACpCT,KAAK,EAAErC,MAAM,CAACgD,SAAU;QAAAT,QAAA,EAAC;MAAgB,EAAO;IAAA,EAC3C,EAKPhC,IAAA,CAACZ,IAAI;MAEL0C,KAAK,EAAErC,MAAM,CAACiD,gBAAiB;MAAAV,QAAA,EAC/BhC,IAAA,CAACN,WAAW;QAACoC,KAAK,EAAE;UAACa,MAAM,EAAC;QAAI,CAAE;QAClCC,IAAI,EAAC,SAAS;QACdC,OAAO,EAAE,YAAa;QACtBC,OAAO,EAAEjB;MAAgB;IAEvB,EACK,EACP3B,KAAA,CAACd,IAAI;MACLiD,UAAU,EAAE,IAAK;MACjBC,kBAAkB,EAAC,QAAQ;MAC3BC,iBAAiB,EAAC,oBAAoB;MACtCT,KAAK,EAAErC,MAAM,CAACsD,YAAa;MAAAf,QAAA,GAC3BhC,IAAA,CAACN,WAAW;QACZkD,IAAI,EAAC,WAAW;QAChBC,OAAO,EAAE,iBAAkB;QAC3BC,OAAO,EAAErC;MAAiB,EAExB,EACFT,IAAA,CAACb,IAAI;QAAC2C,KAAK,EAAErC,MAAM,CAACuD,MAAO;QAACC,EAAE,EAAC,cAAc;QAAAjB,QAAA,EAAEzB;MAAU,EAAQ;IAAA,EAC1D;EAAA,EAkBF;AAGT,CAAC;AAGD,eAAeJ,OAAO"},"metadata":{},"sourceType":"module","externalDependencies":[]}